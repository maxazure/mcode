# MaxAgent 详细设计文档

## 1. 项目结构

```
maxagent/
├── pyproject.toml              # 项目配置 (pip/uv)
├── README.md                   # 项目说明
├── TODO.md                     # 开发待办
├── docs/                       # 文档目录
│   ├── 技术架构.md
│   ├── 详细设计.md
│   ├── 上下文汇总工具.md
│   └── 上下文汇总功能.md
├── src/
│   └── maxagent/               # 主包
│       ├── __init__.py
│       ├── __main__.py         # python -m maxagent 入口
│       ├── cli/                # CLI 层
│       │   ├── __init__.py
│       │   ├── main.py         # Typer App 主入口
│       │   ├── chat.py         # chat 命令 (含 thinking/Pipe/REPL)
│       │   ├── edit.py         # edit 命令
│       │   ├── task.py         # task 命令
│       │   ├── test_cmd.py     # test 命令 (框架检测/运行/生成)
│       │   ├── mcp_cmd.py      # mcp 命令 (MCP 服务器管理)
│       │   ├── auth_cmd.py     # auth 命令 (认证管理)
│       │   └── config_cmd.py   # config 命令
│       ├── core/               # 核心层
│       │   ├── __init__.py
│       │   ├── agent.py        # Agent 基类 (上下文管理/记忆注入)
│       │   ├── orchestrator.py # Agent 编排器
│       │   ├── instructions.py # 指令文件加载器
│       │   ├── prompts.py      # 系统提示词 (Plan-Execute 工作流)
│       │   └── thinking_strategy.py  # Thinking 策略选择器
│       ├── agents/             # Agent 实现
│       │   ├── __init__.py
│       │   ├── architect.py    # Architect Agent
│       │   ├── coder.py        # Coder Agent
│       │   └── tester.py       # Tester Agent
│       ├── tools/              # Tool 实现
│       │   ├── __init__.py     # 工具导出与工厂函数
│       │   ├── base.py         # Tool 基类 (支持 items/properties)
│       │   ├── registry.py     # Tool 注册表
│       │   ├── file.py         # 文件操作工具
│       │   ├── search.py       # 搜索工具
│       │   ├── command.py      # 命令执行工具
│       │   ├── git.py          # Git 工具
│       │   ├── glob.py         # Glob 模式匹配
│       │   ├── grep.py         # Grep 搜索 (支持 ripgrep)
│       │   ├── edit.py         # Edit 工具 (9 种 Replacer 策略)
│       │   ├── webfetch.py     # Web 内容获取
│       │   ├── subagent.py     # SubAgent 委派工具
│       │   ├── todo.py         # Todo 任务管理工具
│       │   └── memory.py       # 长期记忆搜索工具
│       ├── mcp/                # MCP (Model Context Protocol) 模块
│       │   ├── __init__.py
│       │   ├── config.py       # MCP 配置管理
│       │   ├── client.py       # MCP 客户端 (HTTP + Stdio)
│       │   └── tools.py        # MCP 工具集成
│       ├── auth/               # 认证模块
│       │   ├── __init__.py
│       │   └── github_copilot.py  # GitHub Copilot OAuth 认证
│       ├── llm/                # LLM 客户端
│       │   ├── __init__.py
│       │   ├── client.py       # LLM 客户端 (含 thinking 处理)
│       │   ├── copilot_client.py  # GitHub Copilot 客户端
│       │   ├── factory.py      # 客户端工厂 (模型特定配置)
│       │   └── models.py       # 请求/响应模型 (含 thinking_content)
│       ├── config/             # 配置管理
│       │   ├── __init__.py
│       │   ├── loader.py       # 配置加载器 (多 Provider 支持)
│       │   ├── schema.py       # 配置 Schema (含 ModelSpecificConfig)
│       │   └── agent_profiles.py  # Agent 配置文件加载
│       └── utils/              # 工具函数
│           ├── __init__.py
│           ├── console.py      # Rich 控制台
│           ├── diff.py         # Diff 处理
│           ├── tokens.py       # Token 统计
│           └── context_summary.py  # 上下文汇总与记忆
└── tests/                      # 测试目录
    ├── __init__.py
    ├── conftest.py
    ├── test_*.py               # 各模块测试
    └── e2e/                    # 端到端测试
```

---

## 2. 核心模块 API 设计

### 2.1 LLM Client (src/maxagent/llm/client.py)

```python
from dataclasses import dataclass, field
from typing import AsyncIterator, Optional
import httpx

@dataclass
class LLMConfig:
    """LLM 客户端配置"""
    base_url: str = "https://open.bigmodel.cn/api/coding/paas/v4"
    api_key: str = ""
    model: str = "glm-4.6"
    temperature: float = 0.7
    max_tokens: int = 4096
    timeout: float = 60.0
    extra_headers: dict = field(default_factory=dict)
    parallel_tool_calls: bool = True

@dataclass
class Message:
    """消息模型"""
    role: str  # "system" | "user" | "assistant" | "tool"
    content: Optional[str] = None
    tool_calls: Optional[list] = None
    tool_call_id: Optional[str] = None
    name: Optional[str] = None

@dataclass
class ToolCall:
    """工具调用"""
    id: str
    type: str = "function"
    function: dict = field(default_factory=dict)  # {name, arguments}

@dataclass 
class ChatResponse:
    """聊天响应"""
    id: str
    model: str
    content: Optional[str] = None
    tool_calls: Optional[list[ToolCall]] = None
    finish_reason: str = "stop"
    usage: dict = field(default_factory=dict)

class LLMClient:
    """LLM 客户端"""
    
    def __init__(self, config: LLMConfig):
        self.config = config
        self._client = httpx.AsyncClient(
            base_url=config.base_url,
            headers={
                "Authorization": f"Bearer {config.api_key}",
                "Content-Type": "application/json",
                **config.extra_headers
            },
            timeout=config.timeout
        )
    
    async def chat(
        self,
        messages: list[Message],
        tools: Optional[list[dict]] = None,
        stream: bool = False,
        **kwargs
    ) -> ChatResponse | AsyncIterator[str]:
        """发送聊天请求"""
        payload = {
            "model": self.config.model,
            "messages": [self._serialize_message(m) for m in messages],
            "temperature": self.config.temperature,
            "max_tokens": self.config.max_tokens,
            "stream": stream,
            **kwargs
        }
        if tools:
            payload["tools"] = tools
            payload["tool_choice"] = "auto"
        
        if stream:
            return self._stream_response(payload)
        else:
            return await self._send_request(payload)
    
    async def _send_request(self, payload: dict) -> ChatResponse:
        """发送非流式请求"""
        response = await self._client.post("/v1/chat/completions", json=payload)
        response.raise_for_status()
        data = response.json()
        return self._parse_response(data)
    
    async def _stream_response(self, payload: dict) -> AsyncIterator[str]:
        """流式响应生成器"""
        async with self._client.stream("POST", "/v1/chat/completions", json=payload) as response:
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    chunk = line[6:]
                    if chunk == "[DONE]":
                        break
                    # 解析并 yield 内容
                    data = json.loads(chunk)
                    if delta := data["choices"][0].get("delta", {}).get("content"):
                        yield delta
    
    def _serialize_message(self, msg: Message) -> dict:
        """序列化消息"""
        result = {"role": msg.role}
        if msg.content:
            result["content"] = msg.content
        if msg.tool_calls:
            result["tool_calls"] = msg.tool_calls
        if msg.tool_call_id:
            result["tool_call_id"] = msg.tool_call_id
        if msg.name:
            result["name"] = msg.name
        return result
    
    def _parse_response(self, data: dict) -> ChatResponse:
        """解析响应"""
        choice = data["choices"][0]
        message = choice["message"]
        return ChatResponse(
            id=data["id"],
            model=data["model"],
            content=message.get("content"),
            tool_calls=[
                ToolCall(
                    id=tc["id"],
                    type=tc["type"],
                    function=tc["function"]
                )
                for tc in message.get("tool_calls", [])
            ] if message.get("tool_calls") else None,
            finish_reason=choice["finish_reason"],
            usage=data.get("usage", {})
        )
    
    async def close(self):
        """关闭客户端"""
        await self._client.aclose()
```

### 2.2 Tool 系统 (src/maxagent/tools/)

#### 2.2.1 Tool 基类 (base.py)

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Callable, Optional
import json

@dataclass
class ToolParameter:
    """工具参数定义"""
    name: str
    type: str
    description: str
    required: bool = True
    enum: Optional[list] = None

@dataclass
class ToolResult:
    """工具执行结果"""
    success: bool
    output: str
    error: Optional[str] = None
    metadata: dict = field(default_factory=dict)

class BaseTool(ABC):
    """工具基类"""
    
    name: str
    description: str
    parameters: list[ToolParameter]
    risk_level: str = "low"  # "low" | "medium" | "high"
    
    @abstractmethod
    async def execute(self, **kwargs) -> ToolResult:
        """执行工具"""
        pass
    
    def to_openai_schema(self) -> dict:
        """转换为 OpenAI Tool Schema"""
        properties = {}
        required = []
        
        for param in self.parameters:
            prop = {
                "type": param.type,
                "description": param.description
            }
            if param.enum:
                prop["enum"] = param.enum
            properties[param.name] = prop
            if param.required:
                required.append(param.name)
        
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": {
                    "type": "object",
                    "properties": properties,
                    "required": required
                }
            }
        }
```

#### 2.2.2 文件工具 (file.py)

```python
from pathlib import Path
from .base import BaseTool, ToolParameter, ToolResult

class ReadFileTool(BaseTool):
    """读取文件工具"""
    
    name = "read_file"
    description = "读取指定文件的内容"
    parameters = [
        ToolParameter(
            name="path",
            type="string",
            description="要读取的文件路径"
        ),
        ToolParameter(
            name="start_line",
            type="integer",
            description="起始行号 (可选)",
            required=False
        ),
        ToolParameter(
            name="end_line",
            type="integer",
            description="结束行号 (可选)",
            required=False
        )
    ]
    risk_level = "low"
    
    def __init__(self, project_root: Path, security_checker):
        self.project_root = project_root
        self.security_checker = security_checker
    
    async def execute(
        self,
        path: str,
        start_line: int = None,
        end_line: int = None
    ) -> ToolResult:
        try:
            file_path = self.project_root / path
            
            # 安全检查
            if not self.security_checker.is_safe_path(file_path):
                return ToolResult(
                    success=False,
                    output="",
                    error=f"Access denied: {path} matches ignore pattern"
                )
            
            if not file_path.exists():
                return ToolResult(
                    success=False,
                    output="",
                    error=f"File not found: {path}"
                )
            
            content = file_path.read_text(encoding="utf-8")
            
            # 行范围处理
            if start_line or end_line:
                lines = content.splitlines()
                start = (start_line or 1) - 1
                end = end_line or len(lines)
                content = "\n".join(lines[start:end])
            
            return ToolResult(
                success=True,
                output=content,
                metadata={"path": str(file_path), "size": len(content)}
            )
            
        except Exception as e:
            return ToolResult(
                success=False,
                output="",
                error=str(e)
            )

class ListFilesTool(BaseTool):
    """列出文件工具"""
    
    name = "list_files"
    description = "按 glob 模式列出匹配的文件"
    parameters = [
        ToolParameter(
            name="pattern",
            type="string",
            description="glob 模式，如 'src/**/*.py'"
        ),
        ToolParameter(
            name="max_results",
            type="integer",
            description="最大返回数量",
            required=False
        )
    ]
    risk_level = "low"
    
    def __init__(self, project_root: Path, security_checker):
        self.project_root = project_root
        self.security_checker = security_checker
    
    async def execute(
        self,
        pattern: str,
        max_results: int = 100
    ) -> ToolResult:
        try:
            matches = []
            for path in self.project_root.glob(pattern):
                if path.is_file() and self.security_checker.is_safe_path(path):
                    rel_path = path.relative_to(self.project_root)
                    matches.append(str(rel_path))
                    if len(matches) >= max_results:
                        break
            
            return ToolResult(
                success=True,
                output="\n".join(matches),
                metadata={"count": len(matches)}
            )
            
        except Exception as e:
            return ToolResult(
                success=False,
                output="",
                error=str(e)
            )
```

#### 2.2.3 命令执行工具 (command.py)

```python
import asyncio
import shlex
from .base import BaseTool, ToolParameter, ToolResult

class RunCommandTool(BaseTool):
    """执行命令工具"""
    
    name = "run_command"
    description = "在项目目录执行 shell 命令"
    parameters = [
        ToolParameter(
            name="command",
            type="string",
            description="要执行的命令"
        ),
        ToolParameter(
            name="cwd",
            type="string",
            description="工作目录 (相对于项目根目录)",
            required=False
        )
    ]
    risk_level = "high"
    
    def __init__(
        self,
        project_root: Path,
        timeout: int = 30,
        max_output: int = 10000,
        require_confirmation: bool = True,
        whitelist: list[str] = None
    ):
        self.project_root = project_root
        self.timeout = timeout
        self.max_output = max_output
        self.require_confirmation = require_confirmation
        self.whitelist = whitelist or []
        self._confirm_callback = None
    
    def set_confirm_callback(self, callback):
        """设置确认回调"""
        self._confirm_callback = callback
    
    async def execute(
        self,
        command: str,
        cwd: str = None
    ) -> ToolResult:
        try:
            # 白名单检查
            if not self._is_whitelisted(command):
                if self.require_confirmation:
                    if not await self._confirm(command):
                        return ToolResult(
                            success=False,
                            output="",
                            error="Command execution denied by user"
                        )
            
            # 确定工作目录
            work_dir = self.project_root
            if cwd:
                work_dir = self.project_root / cwd
            
            # 执行命令
            process = await asyncio.create_subprocess_shell(
                command,
                cwd=work_dir,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=self.timeout
                )
            except asyncio.TimeoutError:
                process.kill()
                return ToolResult(
                    success=False,
                    output="",
                    error=f"Command timed out after {self.timeout}s"
                )
            
            # 截断输出
            output = stdout.decode("utf-8", errors="replace")
            if len(output) > self.max_output:
                output = output[:self.max_output] + "\n... (truncated)"
            
            error_output = stderr.decode("utf-8", errors="replace")
            
            return ToolResult(
                success=process.returncode == 0,
                output=output,
                error=error_output if error_output else None,
                metadata={"exit_code": process.returncode}
            )
            
        except Exception as e:
            return ToolResult(
                success=False,
                output="",
                error=str(e)
            )
    
    def _is_whitelisted(self, command: str) -> bool:
        """检查命令是否在白名单中"""
        cmd_parts = shlex.split(command)
        if not cmd_parts:
            return False
        return cmd_parts[0] in self.whitelist
    
    async def _confirm(self, command: str) -> bool:
        """请求用户确认"""
        if self._confirm_callback:
            return await self._confirm_callback(command)
        return False
```

#### 2.2.4 Tool 注册表 (registry.py)

```python
from typing import Type
from .base import BaseTool, ToolResult
import json

class ToolRegistry:
    """工具注册表"""
    
    def __init__(self):
        self._tools: dict[str, BaseTool] = {}
    
    def register(self, tool: BaseTool):
        """注册工具"""
        self._tools[tool.name] = tool
    
    def get(self, name: str) -> BaseTool | None:
        """获取工具"""
        return self._tools.get(name)
    
    def list_tools(self) -> list[str]:
        """列出所有工具名"""
        return list(self._tools.keys())
    
    def get_openai_schemas(self) -> list[dict]:
        """获取所有工具的 OpenAI Schema"""
        return [tool.to_openai_schema() for tool in self._tools.values()]
    
    async def execute(self, name: str, arguments: str) -> ToolResult:
        """执行工具调用"""
        tool = self._tools.get(name)
        if not tool:
            return ToolResult(
                success=False,
                output="",
                error=f"Unknown tool: {name}"
            )
        
        try:
            kwargs = json.loads(arguments)
            return await tool.execute(**kwargs)
        except json.JSONDecodeError as e:
            return ToolResult(
                success=False,
                output="",
                error=f"Invalid arguments JSON: {e}"
            )
```

### 2.3 Agent 系统 (src/maxagent/core/agent.py)

```python
from dataclasses import dataclass, field
from typing import Optional
from ..llm.client import LLMClient, Message, ChatResponse
from ..tools.registry import ToolRegistry

@dataclass
class AgentConfig:
    """Agent 配置"""
    name: str
    system_prompt: str
    tools: list[str] = field(default_factory=list)  # 可用工具名列表
    max_iterations: int = 10
    temperature: float = 0.7

class Agent:
    """Agent 基类"""
    
    def __init__(
        self,
        config: AgentConfig,
        llm_client: LLMClient,
        tool_registry: ToolRegistry
    ):
        self.config = config
        self.llm = llm_client
        self.tools = tool_registry
        self.messages: list[Message] = []
    
    async def run(self, task: str) -> str:
        """执行任务"""
        # 初始化消息
        self.messages = [
            Message(role="system", content=self.config.system_prompt),
            Message(role="user", content=task)
        ]
        
        # 获取可用工具
        available_tools = self._get_available_tools()
        
        # Agent 循环
        for _ in range(self.config.max_iterations):
            response = await self.llm.chat(
                messages=self.messages,
                tools=available_tools if available_tools else None,
                temperature=self.config.temperature
            )
            
            # 处理 Tool Calls
            if response.tool_calls:
                # 添加 assistant 消息
                self.messages.append(Message(
                    role="assistant",
                    content=response.content,
                    tool_calls=[
                        {"id": tc.id, "type": tc.type, "function": tc.function}
                        for tc in response.tool_calls
                    ]
                ))
                
                # 执行工具调用
                for tool_call in response.tool_calls:
                    result = await self.tools.execute(
                        tool_call.function["name"],
                        tool_call.function["arguments"]
                    )
                    
                    # 添加工具结果
                    self.messages.append(Message(
                        role="tool",
                        tool_call_id=tool_call.id,
                        name=tool_call.function["name"],
                        content=result.output if result.success else f"Error: {result.error}"
                    ))
            else:
                # 没有 tool_calls，返回最终响应
                return response.content
        
        return "Max iterations reached without completion"
    
    def _get_available_tools(self) -> list[dict]:
        """获取当前 Agent 可用的工具"""
        if not self.config.tools:
            return []
        
        all_schemas = self.tools.get_openai_schemas()
        return [
            schema for schema in all_schemas
            if schema["function"]["name"] in self.config.tools
        ]
```

### 2.4 Agent Orchestrator (src/maxagent/core/orchestrator.py)

```python
from dataclasses import dataclass
from typing import Callable, Optional
from .agent import Agent, AgentConfig
from ..llm.client import LLMClient
from ..tools.registry import ToolRegistry

@dataclass
class TaskResult:
    """任务执行结果"""
    success: bool
    output: str
    patches: list[str] = None  # 生成的 patches
    tests: list[str] = None    # 生成的测试
    summary: str = None

class Orchestrator:
    """Agent 编排器"""
    
    def __init__(
        self,
        llm_client: LLMClient,
        tool_registry: ToolRegistry,
        agent_configs: dict[str, AgentConfig]
    ):
        self.llm = llm_client
        self.tools = tool_registry
        self.agent_configs = agent_configs
        self.agents: dict[str, Agent] = {}
        self._progress_callback: Optional[Callable] = None
    
    def set_progress_callback(self, callback: Callable[[str, str], None]):
        """设置进度回调: callback(agent_name, status)"""
        self._progress_callback = callback
    
    def _get_agent(self, name: str) -> Agent:
        """获取或创建 Agent"""
        if name not in self.agents:
            config = self.agent_configs.get(name)
            if not config:
                raise ValueError(f"Unknown agent: {name}")
            self.agents[name] = Agent(config, self.llm, self.tools)
        return self.agents[name]
    
    def _report_progress(self, agent_name: str, status: str):
        """报告进度"""
        if self._progress_callback:
            self._progress_callback(agent_name, status)
    
    async def execute_task(self, task: str) -> TaskResult:
        """执行复杂任务 (task 命令)"""
        
        # Phase 1: Architect 分析需求
        self._report_progress("architect", "分析需求中...")
        architect = self._get_agent("architect")
        analysis = await architect.run(f"""
分析以下需求，并给出实现方案：

{task}

请输出:
1. 需求理解
2. 涉及的文件列表
3. 具体实现步骤
4. 潜在风险点
""")
        
        # Phase 2: Coder 生成代码
        self._report_progress("coder", "生成代码中...")
        coder = self._get_agent("coder")
        code_result = await coder.run(f"""
根据以下分析方案，生成代码修改:

## 原始需求
{task}

## 架构师分析
{analysis}

请生成所需的代码修改，以 unified diff 格式输出每个文件的 patch。
""")
        
        # Phase 3: Tester 生成测试 (可选)
        self._report_progress("tester", "生成测试中...")
        tester = self._get_agent("tester")
        test_result = await tester.run(f"""
根据以下代码变更，生成或更新测试:

## 代码变更
{code_result}

请生成相应的测试代码。
""")
        
        return TaskResult(
            success=True,
            output=code_result,
            patches=self._extract_patches(code_result),
            tests=self._extract_patches(test_result),
            summary=analysis
        )
    
    async def execute_edit(self, file_path: str, instruction: str) -> TaskResult:
        """执行文件编辑 (edit 命令)"""
        
        coder = self._get_agent("coder")
        result = await coder.run(f"""
请修改文件 {file_path}，按以下指示:

{instruction}

先读取文件内容，然后生成 unified diff 格式的 patch。
""")
        
        return TaskResult(
            success=True,
            output=result,
            patches=self._extract_patches(result)
        )
    
    async def execute_chat(self, message: str, history: list = None) -> str:
        """执行对话 (chat 命令)"""
        
        coder = self._get_agent("coder")
        
        # 如果有历史，添加到 agent
        if history:
            coder.messages = history.copy()
            coder.messages.append({"role": "user", "content": message})
        
        return await coder.run(message)
    
    def _extract_patches(self, text: str) -> list[str]:
        """从文本中提取 unified diff patches"""
        patches = []
        current_patch = []
        in_patch = False
        
        for line in text.split("\n"):
            if line.startswith("```diff") or line.startswith("--- "):
                in_patch = True
                if line.startswith("--- "):
                    current_patch.append(line)
            elif line.startswith("```") and in_patch:
                if current_patch:
                    patches.append("\n".join(current_patch))
                current_patch = []
                in_patch = False
            elif in_patch:
                current_patch.append(line)
        
        return patches
```

---

## 3. CLI 命令设计 (src/maxagent/cli/)

### 3.1 主入口 (main.py)

```python
import typer
from rich.console import Console
from typing import Optional

app = typer.Typer(
    name="llc",
    help="MaxAgent - AI Code Assistant CLI",
    add_completion=True,
    no_args_is_help=True
)

console = Console()

# 导入子命令
from . import chat, edit, task, test, explain, config

app.add_typer(chat.app, name="chat")
app.add_typer(edit.app, name="edit")
app.add_typer(task.app, name="task")
app.add_typer(test.app, name="test")
app.add_typer(explain.app, name="explain")
app.add_typer(config.app, name="config")

@app.callback()
def main(
    verbose: bool = typer.Option(False, "--verbose", "-v", help="详细输出"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="指定模型")
):
    """MaxAgent - 基于 LiteLLM 的 AI 代码助手"""
    pass

def cli():
    """CLI 入口点"""
    app()

if __name__ == "__main__":
    cli()
```

### 3.2 Chat 命令 (chat.py)

```python
import typer
from rich.console import Console
from rich.prompt import Prompt
from rich.panel import Panel
from rich.markdown import Markdown
from typing import Optional
import asyncio

app = typer.Typer(help="对话命令")
console = Console()

@app.callback(invoke_without_command=True)
def chat(
    message: Optional[str] = typer.Argument(None, help="提问内容"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="指定模型"),
    no_history: bool = typer.Option(False, "--no-history", help="不保存历史"),
    stream: bool = typer.Option(True, "--stream/--no-stream", help="流式输出")
):
    """
    与 AI 对话。
    
    示例:
        llc chat "解释这段代码的作用"
        llc chat  # 进入 REPL 模式
    """
    if message:
        # 单次对话
        asyncio.run(_single_chat(message, model, stream))
    else:
        # REPL 模式
        asyncio.run(_repl_mode(model, no_history, stream))

async def _single_chat(message: str, model: str, stream: bool):
    """单次对话"""
    from ..core.orchestrator import Orchestrator
    from ..config.loader import load_config
    
    config = load_config()
    orchestrator = create_orchestrator(config, model)
    
    if stream:
        console.print("[dim]Thinking...[/dim]")
        response = await orchestrator.execute_chat(message)
        console.print(Panel(Markdown(response), title="Assistant"))
    else:
        with console.status("[bold green]Thinking..."):
            response = await orchestrator.execute_chat(message)
        console.print(Panel(Markdown(response), title="Assistant"))

async def _repl_mode(model: str, no_history: bool, stream: bool):
    """REPL 交互模式"""
    console.print("[bold green]MaxAgent Chat Mode[/bold green]")
    console.print("输入 'exit' 或按 Ctrl+C 退出\n")
    
    history = []
    
    while True:
        try:
            user_input = Prompt.ask("[bold blue]You[/bold blue]")
            
            if user_input.lower() in ("exit", "quit", "q"):
                console.print("[dim]Goodbye![/dim]")
                break
            
            if not user_input.strip():
                continue
            
            # 执行对话
            from ..core.orchestrator import Orchestrator
            orchestrator = create_orchestrator(load_config(), model)
            
            history_to_use = None if no_history else history
            response = await orchestrator.execute_chat(user_input, history_to_use)
            
            console.print(Panel(Markdown(response), title="[bold green]Assistant[/bold green]"))
            
            if not no_history:
                history.append({"role": "user", "content": user_input})
                history.append({"role": "assistant", "content": response})
                
        except KeyboardInterrupt:
            console.print("\n[dim]Goodbye![/dim]")
            break
```

### 3.3 Edit 命令 (edit.py)

```python
import typer
from rich.console import Console
from rich.syntax import Syntax
from rich.panel import Panel
from rich.prompt import Confirm
from pathlib import Path
from typing import Optional
import asyncio

app = typer.Typer(help="编辑命令")
console = Console()

@app.callback(invoke_without_command=True)
def edit(
    file: Path = typer.Argument(..., help="要编辑的文件路径"),
    instruction: str = typer.Argument(..., help="编辑指令"),
    apply: bool = typer.Option(False, "--apply", "-a", help="直接应用修改"),
    backup: bool = typer.Option(True, "--backup/--no-backup", help="创建备份")
):
    """
    编辑指定文件。
    
    示例:
        llc edit src/app.ts "增加一个 /healthz 路由"
        llc edit src/utils.py "添加日志记录" --apply
    """
    asyncio.run(_edit_file(file, instruction, apply, backup))

async def _edit_file(file: Path, instruction: str, apply: bool, backup: bool):
    """编辑文件"""
    from ..core.orchestrator import Orchestrator
    from ..config.loader import load_config
    from ..utils.diff import apply_patch, create_backup
    
    if not file.exists():
        console.print(f"[red]文件不存在: {file}[/red]")
        raise typer.Exit(1)
    
    config = load_config()
    orchestrator = create_orchestrator(config)
    
    with console.status("[bold green]生成修改方案..."):
        result = await orchestrator.execute_edit(str(file), instruction)
    
    if not result.patches:
        console.print("[yellow]没有生成修改[/yellow]")
        return
    
    # 显示 diff
    for i, patch in enumerate(result.patches):
        console.print(Panel(
            Syntax(patch, "diff", theme="monokai"),
            title=f"[bold]Patch {i+1}[/bold]"
        ))
    
    # 确认应用
    if apply or Confirm.ask("应用这些修改?"):
        if backup:
            backup_path = create_backup(file)
            console.print(f"[dim]备份已创建: {backup_path}[/dim]")
        
        for patch in result.patches:
            success = apply_patch(patch, file)
            if success:
                console.print(f"[green]已应用修改到 {file}[/green]")
            else:
                console.print(f"[red]应用修改失败[/red]")
```

### 3.4 Task 命令 (task.py)

```python
import typer
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.panel import Panel
from rich.syntax import Syntax
from rich.prompt import Confirm
from typing import Optional
import asyncio

app = typer.Typer(help="任务命令")
console = Console()

@app.callback(invoke_without_command=True)
def task(
    description: str = typer.Argument(..., help="任务描述"),
    apply: bool = typer.Option(False, "--apply", "-a", help="直接应用所有修改"),
    skip_tests: bool = typer.Option(False, "--skip-tests", help="跳过测试生成")
):
    """
    执行复杂任务（涉及多 Agent 协作）。
    
    示例:
        llc task "在 UserService 中增加根据 email 查询用户的 API"
        llc task "为整个项目增加日志中间件" --apply
    """
    asyncio.run(_execute_task(description, apply, skip_tests))

async def _execute_task(description: str, apply: bool, skip_tests: bool):
    """执行任务"""
    from ..core.orchestrator import Orchestrator
    from ..config.loader import load_config
    
    config = load_config()
    orchestrator = create_orchestrator(config)
    
    # 设置进度回调
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task_id = progress.add_task("初始化...", total=None)
        
        def progress_callback(agent_name: str, status: str):
            progress.update(task_id, description=f"[{agent_name}] {status}")
        
        orchestrator.set_progress_callback(progress_callback)
        
        result = await orchestrator.execute_task(description)
    
    # 显示结果
    if result.summary:
        console.print(Panel(result.summary, title="[bold]分析结果[/bold]"))
    
    if result.patches:
        console.print(f"\n[bold]生成了 {len(result.patches)} 个代码修改:[/bold]")
        for i, patch in enumerate(result.patches):
            console.print(Panel(
                Syntax(patch, "diff", theme="monokai"),
                title=f"Patch {i+1}"
            ))
    
    if result.tests and not skip_tests:
        console.print(f"\n[bold]生成了 {len(result.tests)} 个测试:[/bold]")
        for i, test in enumerate(result.tests):
            console.print(Panel(
                Syntax(test, "python", theme="monokai"),
                title=f"Test {i+1}"
            ))
    
    # 确认应用
    if result.patches:
        if apply or Confirm.ask("应用所有修改?"):
            # 应用 patches...
            console.print("[green]修改已应用[/green]")
```

---

## 4. 配置系统 (src/maxagent/config/)

### 4.1 配置 Schema (schema.py)

```python
from pydantic import BaseModel, Field
from typing import Optional
from pathlib import Path

class LiteLLMConfig(BaseModel):
    """LiteLLM 配置"""
    base_url: str = "http://localhost:4000"
    api_key: str = ""

class ModelConfig(BaseModel):
    """模型配置"""
    default: str = "github_copilot/gpt-4"
    temperature: float = 0.7
    max_tokens: int = 4096

class ToolsConfig(BaseModel):
    """工具配置"""
    enabled: list[str] = Field(default_factory=lambda: [
        "read_file", "list_files", "search_code", "apply_patch"
    ])
    disabled: list[str] = Field(default_factory=list)

class SecurityConfig(BaseModel):
    """安全配置"""
    ignore_patterns: list[str] = Field(default_factory=lambda: [
        ".env", ".env.*", "*.pem", "*.key"
    ])
    require_confirmation: list[str] = Field(default_factory=lambda: [
        "write_file", "run_command"
    ])

class AgentPromptConfig(BaseModel):
    """Agent Prompt 配置"""
    system_prompt: str

class AgentsConfig(BaseModel):
    """所有 Agent 配置"""
    architect: AgentPromptConfig = AgentPromptConfig(
        system_prompt="""你是一个资深架构师，负责:
1. 分析用户需求
2. 理解项目结构
3. 制定实现方案
4. 识别潜在风险

请使用可用的工具来了解项目情况，然后给出详细的分析和建议。"""
    )
    coder: AgentPromptConfig = AgentPromptConfig(
        system_prompt="""你是一个代码工程师，负责:
1. 根据方案生成高质量代码
2. 生成 unified diff 格式的 patch
3. 遵循项目的编码规范
4. 添加必要的注释

请确保代码清晰、可维护、符合最佳实践。"""
    )
    tester: AgentPromptConfig = AgentPromptConfig(
        system_prompt="""你是一个测试工程师，负责:
1. 为代码变更生成测试
2. 分析测试结果
3. 提供修复建议

请生成全面的测试用例，覆盖正常和边界情况。"""
    )

class Config(BaseModel):
    """主配置"""
    litellm: LiteLLMConfig = Field(default_factory=LiteLLMConfig)
    model: ModelConfig = Field(default_factory=ModelConfig)
    tools: ToolsConfig = Field(default_factory=ToolsConfig)
    security: SecurityConfig = Field(default_factory=SecurityConfig)
    agents: AgentsConfig = Field(default_factory=AgentsConfig)
```

### 4.2 配置加载器 (loader.py)

```python
from pathlib import Path
from typing import Optional
import yaml
import os
from .schema import Config

def load_config(
    project_path: Optional[Path] = None,
    user_config_path: Optional[Path] = None
) -> Config:
    """
    加载配置，按优先级合并:
    1. 项目配置 (./.llc.yaml)
    2. 用户配置 (~/.llc/config.yaml)
    3. 默认值
    """
    config_data = {}
    
    # 用户配置
    user_config = user_config_path or Path.home() / ".llc" / "config.yaml"
    if user_config.exists():
        with open(user_config) as f:
            user_data = yaml.safe_load(f) or {}
            config_data = _deep_merge(config_data, user_data)
    
    # 项目配置
    project_config = (project_path or Path.cwd()) / ".llc.yaml"
    if project_config.exists():
        with open(project_config) as f:
            project_data = yaml.safe_load(f) or {}
            config_data = _deep_merge(config_data, project_data)
    
    # 环境变量覆盖
    config_data = _apply_env_vars(config_data)
    
    return Config(**config_data)

def _deep_merge(base: dict, override: dict) -> dict:
    """深度合并字典"""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = _deep_merge(result[key], value)
        else:
            result[key] = value
    return result

def _apply_env_vars(config: dict) -> dict:
    """应用环境变量"""
    # LITELLM_API_KEY
    if api_key := os.getenv("LITELLM_API_KEY"):
        config.setdefault("litellm", {})["api_key"] = api_key
    
    # LITELLM_BASE_URL
    if base_url := os.getenv("LITELLM_BASE_URL"):
        config.setdefault("litellm", {})["base_url"] = base_url
    
    # LLC_MODEL
    if model := os.getenv("LLC_MODEL"):
        config.setdefault("model", {})["default"] = model
    
    return config
```

---

## 5. 数据模型总结

| 模型 | 用途 | 位置 |
|------|------|------|
| `LLMConfig` | LLM 客户端配置 | `llm/client.py` |
| `Message` | 聊天消息 | `llm/client.py` |
| `ToolCall` | 工具调用 | `llm/client.py` |
| `ChatResponse` | 聊天响应 | `llm/client.py` |
| `ToolParameter` | 工具参数定义 | `tools/base.py` |
| `ToolResult` | 工具执行结果 | `tools/base.py` |
| `AgentConfig` | Agent 配置 | `core/agent.py` |
| `TaskResult` | 任务执行结果 | `core/orchestrator.py` |
| `Config` | 主配置 | `config/schema.py` |

---

## 6. 新增功能模块

### 6.1 指令文件加载器 (src/maxagent/core/instructions.py)

支持自动加载项目指令文件，优先级从低到高：
1. 全局配置: `~/.llc/MAXAGENT.md`
2. 父目录递归发现
3. 项目根目录

支持的文件名:
- MAXAGENT.md
- AGENTS.md
- CLAUDE.md
- .maxagent

### 6.2 Thinking 策略选择器 (src/maxagent/core/thinking_strategy.py)

三种策略模式:
- **auto** (默认): 根据问题复杂度自动判断
- **enabled**: 始终使用 thinking 模型
- **disabled**: 从不使用 thinking 模型

Auto 模式判断规则:
1. 复杂问题关键词检测 (中英文)
2. 消息长度 > 150 字符
3. 包含代码块
4. 多步骤任务
5. 多个问题 (>=2 个问号)

### 6.3 Test 命令 (src/maxagent/cli/test_cmd.py)

#### 测试框架检测

支持的框架:
| 框架 | 语言 | 检测方式 |
|------|------|----------|
| pytest | Python | pytest.ini, pyproject.toml |
| unittest | Python | import unittest |
| Jest | JS/TS | package.json |
| Vitest | JS/TS | package.json |
| Mocha | JS/TS | package.json |
| Go test | Go | go.mod + *_test.go |
| Cargo test | Rust | Cargo.toml |

#### 命令使用

```bash
# 检测测试框架
llc test --detect
llc test detect

# 运行测试
llc test --run
llc test run
llc test run --coverage
llc test run --watch

# 生成测试 (AI)
llc test --generate src/module.py
llc test generate src/module.py
```

### 6.4 支持的 API Provider

| Provider | 环境变量 | 默认 Base URL | 默认模型 |
|----------|----------|---------------|----------|
| GLM (智谱) | `GLM_API_KEY` | `https://open.bigmodel.cn/api/paas/v4` | `glm-4.6` |
| OpenAI | `OPENAI_API_KEY` | `https://api.openai.com/v1` | `gpt-4` |
| LiteLLM | `LITELLM_API_KEY` | `http://localhost:4000` | 自定义 |

### 6.5 Thinking 模型支持

| Provider | 模型 | 格式 |
|----------|------|------|
| GLM | glm-4.6 | `<think>...</think>` 标签 |
| DeepSeek | deepseek-reasoner | `reasoning_content` 字段 |
| DeepSeek | deepseek-r1 | `reasoning_content` 字段 |

### 6.6 MCP (Model Context Protocol) 模块

#### 6.6.1 概述

MCP 是 Anthropic 推出的模型上下文协议，允许 AI 模型访问外部工具和数据源。
MaxAgent 支持通过 **HTTP** 和 **Stdio** 两种传输方式连接 MCP 服务器。

#### 6.6.2 配置管理 (src/maxagent/mcp/config.py)

```python
from dataclasses import dataclass, field
from typing import Optional
from pathlib import Path
import json
import os

@dataclass
class MCPServerConfig:
    """MCP 服务器配置"""
    name: str                                    # 服务器名称
    type: str = "http"                           # 传输类型: "http" | "stdio"
    url: Optional[str] = None                    # HTTP URL (type=http 时必填)
    command: Optional[str] = None                # 命令 (type=stdio 时必填)
    args: list[str] = field(default_factory=list)  # 命令参数
    env: dict[str, str] = field(default_factory=dict)  # 环境变量
    headers: dict[str, str] = field(default_factory=dict)  # HTTP headers
    enabled: bool = True                         # 是否启用
    
    def get_resolved_env(self) -> dict[str, str]:
        """获取解析后的环境变量 (支持 ${VAR} 替换)"""
        resolved = {}
        for key, value in self.env.items():
            resolved[key] = self._resolve_env_var(value)
        return resolved
    
    def get_resolved_command(self) -> str:
        """获取解析后的命令"""
        return self._resolve_env_var(self.command) if self.command else ""
    
    @staticmethod
    def _resolve_env_var(value: str) -> str:
        """解析环境变量引用"""
        import re
        pattern = r'\$\{([^}]+)\}'
        def replacer(match):
            var_name = match.group(1)
            return os.environ.get(var_name, match.group(0))
        return re.sub(pattern, replacer, value)

@dataclass
class MCPConfig:
    """MCP 配置容器"""
    servers: dict[str, MCPServerConfig] = field(default_factory=dict)
    config_path: Path = Path.home() / ".config" / "maxagent" / "mcp_servers.json"
    
    def add_server(self, config: MCPServerConfig) -> None:
        """添加服务器配置"""
        self.servers[config.name] = config
        self.save()
    
    def remove_server(self, name: str) -> bool:
        """移除服务器配置"""
        if name in self.servers:
            del self.servers[name]
            self.save()
            return True
        return False
    
    def save(self) -> None:
        """保存配置到文件"""
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)
    
    @classmethod
    def load(cls) -> "MCPConfig":
        """从文件加载配置"""
        config = cls()
        if config.config_path.exists():
            with open(config.config_path) as f:
                data = json.load(f)
                for name, server_data in data.get("servers", {}).items():
                    config.servers[name] = MCPServerConfig(**server_data)
        return config
```

#### 6.6.3 MCP 客户端 (src/maxagent/mcp/client.py)

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Optional
import asyncio
import json
import httpx

@dataclass
class MCPToolDefinition:
    """MCP 工具定义"""
    name: str
    description: str
    input_schema: dict = field(default_factory=dict)

class MCPClientBase(ABC):
    """MCP 客户端基类"""
    
    @abstractmethod
    async def connect(self) -> None:
        """建立连接"""
        pass
    
    @abstractmethod
    async def list_tools(self) -> list[MCPToolDefinition]:
        """获取工具列表"""
        pass
    
    @abstractmethod
    async def call_tool(self, name: str, arguments: dict) -> Any:
        """调用工具"""
        pass
    
    @abstractmethod
    async def close(self) -> None:
        """关闭连接"""
        pass

class MCPHttpClient(MCPClientBase):
    """HTTP 传输 MCP 客户端 (Streamable HTTP)"""
    
    def __init__(self, config: MCPServerConfig):
        self.config = config
        self.client: Optional[httpx.AsyncClient] = None
        self.session_id: Optional[str] = None
        self._request_id = 0
    
    async def connect(self) -> None:
        """建立 HTTP 连接并初始化会话"""
        headers = self.config.headers.copy()
        headers["Content-Type"] = "application/json"
        self.client = httpx.AsyncClient(headers=headers, timeout=30.0)
        
        # 发送 initialize 请求
        response = await self._send_request("initialize", {
            "protocolVersion": "2024-11-05",
            "capabilities": {},
            "clientInfo": {"name": "maxagent", "version": "1.0.0"}
        })
        
        # 保存 session ID (如果返回)
        if "Mcp-Session-Id" in response.get("headers", {}):
            self.session_id = response["headers"]["Mcp-Session-Id"]
    
    async def list_tools(self) -> list[MCPToolDefinition]:
        """获取工具列表"""
        response = await self._send_request("tools/list", {})
        tools = []
        for tool in response.get("result", {}).get("tools", []):
            tools.append(MCPToolDefinition(
                name=tool["name"],
                description=tool.get("description", ""),
                input_schema=tool.get("inputSchema", {})
            ))
        return tools
    
    async def call_tool(self, name: str, arguments: dict) -> Any:
        """调用工具"""
        response = await self._send_request("tools/call", {
            "name": name,
            "arguments": arguments
        })
        return response.get("result", {}).get("content", [])
    
    async def _send_request(self, method: str, params: dict) -> dict:
        """发送 JSON-RPC 请求"""
        self._request_id += 1
        payload = {
            "jsonrpc": "2.0",
            "id": self._request_id,
            "method": method,
            "params": params
        }
        
        headers = {}
        if self.session_id:
            headers["Mcp-Session-Id"] = self.session_id
        
        response = await self.client.post(
            self.config.url,
            json=payload,
            headers=headers
        )
        response.raise_for_status()
        return response.json()
    
    async def close(self) -> None:
        """关闭连接"""
        if self.client:
            await self.client.aclose()

class MCPStdioClient(MCPClientBase):
    """Stdio 传输 MCP 客户端 (子进程通信)"""
    
    def __init__(self, config: MCPServerConfig):
        self.config = config
        self.process: Optional[asyncio.subprocess.Process] = None
        self._request_id = 0
        self._pending_requests: dict[int, asyncio.Future] = {}
        self._reader_task: Optional[asyncio.Task] = None
    
    async def connect(self) -> None:
        """启动子进程并建立连接"""
        env = {**os.environ, **self.config.get_resolved_env()}
        cmd = self.config.get_resolved_command()
        args = self.config.args
        
        self.process = await asyncio.create_subprocess_exec(
            cmd, *args,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            env=env
        )
        
        # 启动响应读取任务
        self._reader_task = asyncio.create_task(self._read_responses())
        
        # 发送 initialize 请求
        await self._send_request("initialize", {
            "protocolVersion": "2024-11-05",
            "capabilities": {},
            "clientInfo": {"name": "maxagent", "version": "1.0.0"}
        })
    
    async def list_tools(self) -> list[MCPToolDefinition]:
        """获取工具列表"""
        response = await self._send_request("tools/list", {})
        tools = []
        for tool in response.get("tools", []):
            tools.append(MCPToolDefinition(
                name=tool["name"],
                description=tool.get("description", ""),
                input_schema=tool.get("inputSchema", {})
            ))
        return tools
    
    async def call_tool(self, name: str, arguments: dict) -> Any:
        """调用工具"""
        response = await self._send_request("tools/call", {
            "name": name,
            "arguments": arguments
        })
        return response.get("content", [])
    
    async def _send_request(self, method: str, params: dict) -> dict:
        """发送 JSON-RPC 请求到 stdin"""
        self._request_id += 1
        request_id = self._request_id
        
        payload = {
            "jsonrpc": "2.0",
            "id": request_id,
            "method": method,
            "params": params
        }
        
        # 创建 Future 等待响应
        future = asyncio.Future()
        self._pending_requests[request_id] = future
        
        # 写入 stdin
        line = json.dumps(payload) + "\n"
        self.process.stdin.write(line.encode())
        await self.process.stdin.drain()
        
        # 等待响应
        return await future
    
    async def _read_responses(self) -> None:
        """读取 stdout 响应"""
        while True:
            line = await self.process.stdout.readline()
            if not line:
                break
            
            try:
                data = json.loads(line.decode())
                request_id = data.get("id")
                if request_id in self._pending_requests:
                    future = self._pending_requests.pop(request_id)
                    if "error" in data:
                        future.set_exception(Exception(data["error"]))
                    else:
                        future.set_result(data.get("result", {}))
            except json.JSONDecodeError:
                continue
    
    async def close(self) -> None:
        """关闭连接和进程"""
        if self._reader_task:
            self._reader_task.cancel()
        if self.process:
            self.process.terminate()
            await self.process.wait()

def create_mcp_client(config: MCPServerConfig) -> MCPClientBase:
    """工厂函数: 根据配置创建 MCP 客户端"""
    if config.type == "stdio":
        return MCPStdioClient(config)
    else:
        return MCPHttpClient(config)
```

#### 6.6.4 MCP 工具集成 (src/maxagent/mcp/tools.py)

```python
from dataclasses import dataclass
from typing import Any, Optional
from ..tools.base import BaseTool, ToolParameter, ToolResult
from .client import MCPClientBase, MCPToolDefinition

class MCPTool(BaseTool):
    """MCP 工具包装类"""
    
    def __init__(
        self,
        definition: MCPToolDefinition,
        client: MCPClientBase,
        server_name: str
    ):
        self.definition = definition
        self.client = client
        self.server_name = server_name
        
        # 设置 BaseTool 属性
        self.name = f"mcp_{server_name}_{definition.name}"
        self.description = f"[MCP:{server_name}] {definition.description}"
        self.parameters = self._convert_parameters(definition.input_schema)
        self.risk_level = "medium"
    
    def _convert_parameters(self, schema: dict) -> list[ToolParameter]:
        """转换 JSON Schema 为 ToolParameter"""
        params = []
        properties = schema.get("properties", {})
        required = schema.get("required", [])
        
        for name, prop in properties.items():
            params.append(ToolParameter(
                name=name,
                type=prop.get("type", "string"),
                description=prop.get("description", ""),
                required=name in required
            ))
        return params
    
    async def execute(self, **kwargs) -> ToolResult:
        """执行 MCP 工具调用"""
        try:
            result = await self.client.call_tool(
                self.definition.name,
                kwargs
            )
            
            # 格式化输出
            output = ""
            for item in result:
                if item.get("type") == "text":
                    output += item.get("text", "")
                elif item.get("type") == "image":
                    output += f"[Image: {item.get('mimeType', 'image')}]"
            
            return ToolResult(
                success=True,
                output=output,
                metadata={"server": self.server_name, "tool": self.definition.name}
            )
        except Exception as e:
            return ToolResult(
                success=False,
                output="",
                error=str(e)
            )

class MCPToolRegistry:
    """MCP 工具注册表"""
    
    def __init__(self):
        self._clients: dict[str, MCPClientBase] = {}
        self._tools: dict[str, MCPTool] = {}
    
    async def register_server(
        self,
        client: MCPClientBase,
        server_name: str
    ) -> list[MCPTool]:
        """注册 MCP 服务器并获取工具"""
        await client.connect()
        self._clients[server_name] = client
        
        tools = []
        for definition in await client.list_tools():
            tool = MCPTool(definition, client, server_name)
            self._tools[tool.name] = tool
            tools.append(tool)
        
        return tools
    
    def get_tools(self) -> list[MCPTool]:
        """获取所有 MCP 工具"""
        return list(self._tools.values())
    
    def get_openai_schemas(self) -> list[dict]:
        """获取所有工具的 OpenAI Schema"""
        return [tool.to_openai_schema() for tool in self._tools.values()]
    
    async def close_all(self) -> None:
        """关闭所有客户端"""
        for client in self._clients.values():
            await client.close()
```

#### 6.6.5 CLI 命令 (src/maxagent/cli/mcp_cmd.py)

```bash
# 添加 HTTP MCP 服务器
llc mcp add web-reader https://api.example.com/mcp \
    --header "Authorization: Bearer ${API_KEY}"

# 添加 Stdio MCP 服务器
llc mcp add searxng --command mcp-searxng \
    --env "SEARXNG_URL=http://localhost:8888"

# 添加带参数的 Stdio 服务器
llc mcp add myserver --command python \
    --arg "-m" --arg "my_mcp_server"

# Claude 兼容语法 (使用 -- 分隔符)
llc mcp add searxng --transport stdio -- env SEARXNG_URL=http://localhost:8888 mcp-searxng

# 列出服务器 (自动测试连接状态)
llc mcp list              # 列出并测试所有服务器连接
llc mcp list -v           # 详细模式，显示环境变量和错误信息
llc mcp list --no-test    # 跳过连接测试，快速列出

# 测试单个服务器连接
llc mcp test <name>

# 列出工具
llc mcp tools
llc mcp tools <server_name>

# 启用/禁用
llc mcp enable <name>
llc mcp disable <name>

# 移除
llc mcp remove <name>

# 查看配置
llc mcp config
```

##### `llc mcp list` 输出示例

```
Testing server connections...

                                  MCP Servers                                   
┏━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ Name       ┃ Type  ┃ URL/Command    ┃ Status  ┃ Connection   ┃
┡━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ web-reader │ http  │ https://open.… │ Enabled │ OK (1 tools) │
│ searxng    │ stdio │ mcp-searxng    │ Enabled │ OK (2 tools) │
└────────────┴───────┴────────────────┴─────────┴──────────────┘
```

详细模式 (`-v`) 输出:

```
Testing server connections...

                                  MCP Servers                                   
┏━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Name       ┃ Type  ┃ URL/Command    ┃ Status  ┃ Connection   ┃ Details       ┃
┡━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ web-reader │ http  │ https://open.… │ Enabled │ OK (1 tools) │ Headers:      │
│            │       │                │         │              │ Authorization │
│ searxng    │ stdio │ mcp-searxng    │ Enabled │ OK (2 tools) │ Env:          │
│            │       │                │         │              │ SEARXNG_URL   │
└────────────┴───────┴────────────────┴─────────┴──────────────┴───────────────┘
```

#### 6.6.6 配置文件格式

```json
{
  "servers": {
    "web-reader": {
      "name": "web-reader",
      "type": "http",
      "url": "https://open.bigmodel.cn/api/mcp/web_reader/mcp",
      "headers": {
        "Authorization": "Bearer ${ZHIPU_KEY}"
      },
      "enabled": true
    },
    "searxng": {
      "name": "searxng",
      "type": "stdio",
      "command": "mcp-searxng",
      "args": [],
      "env": {
        "SEARXNG_URL": "http://192.168.31.205:8888"
      },
      "enabled": true
    }
  }
}
```

---

## 6.7 Edit 工具 (src/maxagent/tools/edit.py)

### 6.7.1 概述

Edit 工具使用 **Search-and-Replace** 方式精确修改文件，避免了传统 `write_file` 重写整个文件导致代码丢失的问题。
该设计参考了 Claude Code 的 `str_replace` 和 OpenCode 的 edit.ts 实现。

### 6.7.2 核心类

```python
from dataclasses import dataclass
from typing import Optional, Callable
from pathlib import Path

@dataclass
class EditTool(BaseTool):
    """Edit 工具 - 使用 search-and-replace 精确修改文件"""
    
    name = "edit"
    description = """使用 search-and-replace 精确修改现有文件的内容。
    
使用前必须先用 read_file 工具读取文件内容，以确保准确匹配。

参数:
- file_path: 要修改的文件路径 (相对于项目根目录)
- old_string: 要被替换的原始内容 (必须精确匹配文件中的现有内容)
- new_string: 替换后的新内容
- replace_all: 是否替换所有匹配项 (默认 false，只替换第一个)

返回: 显示修改的 unified diff 格式"""
    
    parameters = [
        ToolParameter(
            name="file_path",
            type="string",
            description="要修改的文件路径"
        ),
        ToolParameter(
            name="old_string",
            type="string",
            description="要被替换的原始内容"
        ),
        ToolParameter(
            name="new_string",
            type="string",
            description="替换后的新内容"
        ),
        ToolParameter(
            name="replace_all",
            type="boolean",
            description="是否替换所有匹配项",
            required=False
        )
    ]
    risk_level = "medium"
```

### 6.7.3 Replacer 策略

Edit 工具实现了 **9 种智能匹配策略**，按优先级依次尝试：

| 优先级 | 策略名称 | 描述 |
|--------|----------|------|
| 1 | `simple_replacer` | 精确字符串匹配 |
| 2 | `line_trimmed_replacer` | 行首尾空白修剪匹配 |
| 3 | `block_anchor_replacer` | 块锚点匹配 (首尾行 + Levenshtein 相似度) |
| 4 | `whitespace_normalized_replacer` | 空白标准化匹配 |
| 5 | `indentation_flexible_replacer` | 缩进灵活匹配 |
| 6 | `escape_normalized_replacer` | 转义字符标准化 |
| 7 | `trimmed_boundary_replacer` | 边界修剪匹配 |
| 8 | `context_aware_replacer` | 上下文感知匹配 |
| 9 | `multi_occurrence_replacer` | 多次出现匹配 (选择最佳匹配) |

### 6.7.4 核心函数

```python
def levenshtein_distance(s1: str, s2: str) -> int:
    """计算两个字符串的编辑距离"""
    pass

def replace_content(
    original: str,
    old_string: str,
    new_string: str,
    replace_all: bool = False
) -> tuple[str, bool]:
    """
    执行内容替换，按策略优先级尝试匹配
    
    Returns:
        (替换后的内容, 是否成功替换)
    """
    pass

def create_unified_diff(
    original: str,
    modified: str,
    file_path: str
) -> str:
    """生成 unified diff 格式的差异"""
    pass
```

### 6.7.5 使用示例

```python
# 示例 1: 添加 docstring
result = await edit_tool.execute(
    file_path="src/utils.py",
    old_string="def foo():\n    return 1",
    new_string='def foo():\n    """Docstring."""\n    return 1'
)

# 示例 2: 批量重命名变量
result = await edit_tool.execute(
    file_path="src/app.py",
    old_string="user_name",
    new_string="username",
    replace_all=True
)

# 示例 3: 修改函数实现
result = await edit_tool.execute(
    file_path="src/calculator.py",
    old_string='''def add(a, b):
    return a + b''',
    new_string='''def add(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b'''
)
```

### 6.7.6 CLI 使用

```bash
# 在 chat 模式中使用 edit 工具
llc chat "给 src/utils.py 中的 calculate 函数添加类型注解"

# LLM 会自动:
# 1. 先调用 read_file 读取文件内容
# 2. 使用 edit 工具进行精确修改
# 3. 返回 unified diff 显示修改
```

### 6.7.7 工具提示词

```markdown
## Editing Files - IMPORTANT

When modifying existing files, ALWAYS use the `edit` tool instead of `write_file`:

- `edit`: Search-and-replace for precise modifications (PREFERRED)
- `write_file`: Only for creating NEW files

### Edit Tool Usage:
1. FIRST read the file with `read_file` to see current content
2. Use `edit` with exact `old_string` matching the current content
3. The `new_string` contains your modifications

### Example:
```
# Adding a docstring to a function
edit(
  file_path="src/utils.py",
  old_string="def foo():\n    return 1",
  new_string='def foo():\n    """Docstring."""\n    return 1'
)
```
```

### 6.7.8 安全机制

1. **必须先读取文件**: 工具要求 LLM 先使用 `read_file` 了解文件内容
2. **精确匹配要求**: `old_string` 必须与文件内容精确匹配
3. **唯一性检查**: 默认模式下，如果 `old_string` 匹配多处会报错
4. **备份支持**: 可通过配置启用自动备份
5. **Unified Diff 输出**: 返回清晰的差异格式，便于用户审查

---

## 7. 测试覆盖

### 7.1 单元测试

测试文件位于 `tests/` 目录：

| 测试文件 | 测试内容 |
|----------|----------|
| `test_thinking_strategy.py` | Thinking 策略选择器测试 |
| `test_test_cmd.py` | 测试命令和框架检测测试 |
| `test_config_loader.py` | 配置加载器测试 |
| `test_tools_base.py` | 工具基类测试 |
| `test_tokens.py` | Token 统计功能测试 |
| `test_github_copilot.py` | GitHub Copilot 认证测试 |
| `test_mcp.py` | MCP 模块测试 (配置、HTTP、Stdio、连接测试) |
| `test_edit.py` | Edit 工具测试 (9 种 Replacer 策略) |
| `test_todo.py` | Todo 工具测试 (CRUD、工作流测试) |
| `test_context.py` | 上下文管理测试 (Token 计数、压缩) |
| `test_context_summary.py` | 上下文汇总与记忆卡片测试 |
| `test_model_specific_config.py` | 模型特定配置测试 |
| `test_agent_tool_cache.py` | Agent 工具调用缓存测试 |
| `test_agent_file_read_dedup.py` | 文件读取去重测试 |
| `test_memory_injection.py` | 记忆自动注入测试 |
| `test_subagent_explore_batched.py` | SubAgent 批量探索测试 |

### 7.2 运行测试

```bash
# 运行所有测试
pytest tests/ -v

# 运行特定测试文件
pytest tests/test_edit.py -v

# 生成覆盖率报告
pytest tests/ --cov=src/maxagent --cov-report=html

# 运行端到端测试
pytest tests/e2e/ -v
```

### 7.3 测试 Fixtures

定义在 `tests/conftest.py`：
- `temp_dir`: 创建临时目录
- `project_root`: 创建模拟项目结构
- `clean_env`: 清理环境变量
- `mock_config_data`: 模拟配置数据

---

## 8. 新增功能模块

### 8.1 SubAgent 委派系统 (src/maxagent/tools/subagent.py)

SubAgent 工具允许主代理将复杂任务委派给专业化子代理：

```python
class SubAgentTool(BaseTool):
    """启动专用子代理处理复杂任务"""
    
    # 支持的代理类型
    AGENT_TYPES = {
        "explore": "快速代码库探索和搜索",
        "architect": "需求分析与方案设计",
        "coder": "代码生成与修改",
        "tester": "测试生成与分析",
        "shell": "CLI 环境操作（安装依赖、运行服务器等）",
        "general": "通用任务处理"
    }
```

### 8.2 Todo 任务管理 (src/maxagent/tools/todo.py)

结构化待办列表管理，支持 Plan-Execute 工作流：

```python
@dataclass
class TodoItem:
    id: str
    content: str
    status: TodoStatus  # pending/in_progress/completed/cancelled
    priority: TodoPriority  # high/medium/low
    file_path: Optional[str] = None  # 目标文件路径
    details: Optional[str] = None  # 技术实现细节
```

### 8.3 长期记忆系统 (src/maxagent/utils/context_summary.py)

上下文汇总与记忆卡片机制：

```python
@dataclass
class MemoryCard:
    content: str       # 记忆内容
    type: str          # goal/decision/constraint/todo/code/fact
    tags: list[str]    # 主题关键词
    created_at: str    # 生成时间

class MemoryStore:
    """长期记忆存储"""
    
    def search(self, query: str, top_k: int = 5) -> list[MemoryCard]:
        """搜索相关记忆"""
        pass
    
    def add(self, cards: list[MemoryCard]) -> None:
        """添加记忆卡片"""
        pass
```

### 8.4 模型特定配置 (src/maxagent/config/schema.py)

支持按模型或 Provider/模型 配置参数：

```yaml
model:
  default: gpt-4o
  max_tokens: 4096
  models:
    gpt-4o:
      max_tokens: 8192
      context_length: 128000
    github_copilot/gpt-4o:  # Provider 特定配置
      max_tokens: 4096
      context_length: 100000
```

配置优先级: Provider 特定 > 模型特定 > 硬编码默认值 > 全局配置

---

## 9. 下一步开发计划

详见 TODO.md
