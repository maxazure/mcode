# MaxAgent 技术架构文档

## 1. 项目概述

**项目名称**: MaxAgent - 基于 LiteLLM + GitHub Copilot 的 CLI 代码助手

**目标**: 提供一个类似 Claude Code / Copilot CLI 的本地命令行工具，通过 LiteLLM 作为代理层接通 GitHub Copilot API，支持智能编程辅助。

---

## 2. 技术选型决策

### 2.1 开发语言: Python

| 候选方案 | 优点 | 缺点 | 结论 |
|---------|------|------|------|
| **Python** | 生态丰富、LiteLLM 原生支持、开发速度快、AI/ML 工具链完善 | 冷启动稍慢 | **选择** |
| Go | 启动快、单二进制部署 | LiteLLM 无 Go SDK、需额外 HTTP 封装 | 不选 |
| Node.js | 生态丰富 | 依赖管理复杂、类型安全较弱 | 不选 |

### 2.2 CLI 框架: Typer + Rich

| 候选方案 | 优点 | 缺点 | 结论 |
|---------|------|------|------|
| **Typer** | 类型提示定义参数、自动补全、Rich 集成 | 依赖 Click | **选择** |
| Click | 成熟稳定、功能全面 | 代码量较多 | 备选 |
| argparse | 零依赖 | 开发体验差 | 不选 |

### 2.3 Agent 框架: 原生实现

| 候选方案 | 优点 | 缺点 | 结论 |
|---------|------|------|------|
| **原生实现** | 最轻量、最快冷启动、完全可控 | 开发量较大 | **选择** |
| LangChain | 快速开发 | 依赖重、启动慢 | 不选 |
| LangGraph | 状态管理好 | 学习曲线陡峭 | 不选 |
| CrewAI | 角色概念直观 | 包体积大 | 不选 |

**原因**: CLI 工具对冷启动速度要求高，原生实现可保持 <0.5s 启动时间。

### 2.4 LLM 接入: LiteLLM

LiteLLM 作为统一网关层，提供:
- 对接 100+ LLM Provider (包括 GitHub Copilot)
- OpenAI 兼容 API
- Tool/Function Calling 支持
- Token 用量统计
- 模型路由和负载均衡

---

## 3. 系统架构

### 3.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                         用户终端                                  │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      CLI 层 (Typer + Rich)                       │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐   │
│  │  chat   │ │  edit   │ │  task   │ │  test   │ │ config  │   │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘   │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Agent Orchestrator                            │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │  Architect   │  │    Coder     │  │   Tester     │          │
│  │    Agent     │  │    Agent     │  │    Agent     │          │
│  └──────────────┘  └──────────────┘  └──────────────┘          │
│                                                                  │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                   Tool Registry                            │  │
│  │  read_file | write_file | search_code | run_command | git  │  │
│  └───────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      LLM Client Layer                            │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    LiteLLM SDK                           │    │
│  │  - OpenAI 兼容 API                                       │    │
│  │  - Tool Calling 支持                                     │    │
│  │  - Streaming 支持                                        │    │
│  └─────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      LLM Providers                               │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐       │
│  │GitHub Copilot │  │    OpenAI     │  │   Anthropic   │       │
│  └───────────────┘  └───────────────┘  └───────────────┘       │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 分层架构说明

#### Layer 1: CLI 层
- **职责**: 用户交互、命令解析、终端渲染
- **技术**: Typer (命令解析) + Rich (终端 UI)
- **组件**:
  - `chat`: 通用对话/代码问答
  - `edit`: 文件级修改
  - `task`: 需求级任务执行
  - `test`: 测试生成与执行
  - `explain`: 代码解释
  - `config`: 配置管理

#### Layer 2: Agent Orchestrator
- **职责**: Agent 编排、任务分解、工具调用
- **组件**:
  - **Architect Agent**: 需求分析、任务拆解
  - **Coder Agent**: 代码生成、Patch 创建
  - **Tester Agent**: 测试生成、结果分析
  - **Tool Registry**: 工具注册和调用

#### Layer 3: LLM Client
- **职责**: LLM API 调用、Token 管理、流式输出
- **技术**: LiteLLM Python SDK / httpx

#### Layer 4: LLM Providers
- **主要**: GitHub Copilot (通过 LiteLLM 代理)
- **备选**: OpenAI, Anthropic, Azure OpenAI 等

---

## 4. 核心模块设计

### 4.1 LiteLLM + GitHub Copilot 集成

```python
# 配置示例: config.yaml
model_list:
  - model_name: copilot-gpt-4
    litellm_params:
      model: github_copilot/gpt-4
      extra_headers:
        editor-version: "vscode/1.85.1"
        Copilot-Integration-Id: "vscode-chat"
```

**关键点**:
- GitHub Copilot 使用 OAuth Device Flow 认证
- 首次使用需通过 GitHub 授权
- Token 自动存储在 `~/.config/litellm/github_copilot/`

### 4.2 Tool 系统设计

```python
# OpenAI-style Tool Schema
tools = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "读取指定文件内容",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "文件路径"
                    }
                },
                "required": ["path"]
            }
        }
    }
]
```

**支持的 Tools**:

| Tool | 功能 | 安全级别 |
|------|------|---------|
| `read_file` | 读取文件内容 | 低风险 |
| `list_files` | 按 glob 匹配文件 | 低风险 |
| `search_code` | 代码搜索 | 低风险 |
| `apply_patch` | 应用 unified diff | 中风险 |
| `write_file` | 重写文件 | 高风险 |
| `run_command` | 执行命令 | 高风险 |
| `git_diff` | 获取 Git 差异 | 低风险 |
| `git_status` | 获取 Git 状态 | 低风险 |

### 4.3 Agent 编排模式

```
┌─────────────────────────────────────────────────────────────┐
│                      Task 命令流程                           │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
                    ┌───────────────┐
                    │   用户输入    │
                    │   需求描述    │
                    └───────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                    Architect Agent                           │
│  - 分析需求                                                  │
│  - 调用 list_files/search_code 了解项目结构                  │
│  - 输出: 任务分解 + 修改方案                                 │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                      Coder Agent                             │
│  - 按 Architect 方案执行                                     │
│  - 调用 read_file 获取文件内容                               │
│  - 生成 unified diff patch                                   │
│  - 输出: patch 列表                                          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                     Tester Agent (可选)                      │
│  - 为变更生成测试代码                                        │
│  - 调用 run_command 执行测试                                 │
│  - 分析测试结果                                              │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
                    ┌───────────────┐
                    │   用户确认    │
                    │   应用 Patch  │
                    └───────────────┘
```

---

## 5. 配置系统

### 5.1 配置文件层级

```
优先级 (高 → 低):
1. 命令行参数
2. 环境变量
3. 项目配置: ./.llc.yaml
4. 用户配置: ~/.llc/config.yaml
5. 默认值
```

### 5.2 配置文件结构

```yaml
# ~/.llc/config.yaml
litellm:
  base_url: "http://localhost:4000"  # LiteLLM Proxy 地址
  api_key: "${LITELLM_API_KEY}"      # 支持环境变量

model:
  default: "github_copilot/gpt-4"
  temperature: 0.7
  max_tokens: 4096

tools:
  enabled:
    - read_file
    - list_files
    - search_code
    - apply_patch
  disabled:
    - run_command  # 按需禁用危险工具

security:
  ignore_patterns:
    - ".env"
    - "*.pem"
    - "*.key"
  require_confirmation:
    - write_file
    - run_command

agents:
  architect:
    system_prompt: |
      你是一个资深架构师，负责分析需求并制定实现方案...
  coder:
    system_prompt: |
      你是一个代码工程师，负责根据方案生成高质量代码...
```

---

## 6. 安全设计

### 6.1 敏感文件保护

```python
DEFAULT_IGNORE_PATTERNS = [
    ".env", ".env.*",
    "*.pem", "*.key", "*.p12",
    "**/secrets/**",
    "**/credentials/**",
    ".git/config",  # 可能包含 token
]
```

### 6.2 命令执行沙箱

```python
class CommandExecutor:
    def __init__(self, config: Config):
        self.timeout = config.command_timeout  # 默认 30s
        self.whitelist = config.command_whitelist
        self.require_confirmation = config.require_command_confirmation
    
    async def execute(self, cmd: str, cwd: str) -> CommandResult:
        # 1. 白名单检查
        if not self._is_whitelisted(cmd):
            if self.require_confirmation:
                if not await self._confirm_execution(cmd):
                    raise ExecutionDenied()
        
        # 2. 执行命令 (带超时)
        # 3. 输出截断 (防止 token 浪费)
```

### 6.3 Patch 应用安全

```python
class PatchApplier:
    def apply(self, patch: str, target_file: str) -> ApplyResult:
        # 1. 创建备份
        backup_path = self._create_backup(target_file)
        
        # 2. 验证 patch 格式
        if not self._validate_patch(patch):
            raise InvalidPatch()
        
        # 3. 应用 patch
        try:
            result = self._apply_unified_diff(patch, target_file)
            return ApplyResult(success=True, backup=backup_path)
        except Exception as e:
            # 4. 失败时恢复
            self._restore_from_backup(backup_path, target_file)
            raise
```

---

## 7. 性能优化

### 7.1 冷启动优化

| 策略 | 说明 |
|------|------|
| 延迟导入 | 非必要模块延迟加载 |
| 精简依赖 | 仅引入必要包 |
| 编译缓存 | 使用 `__pycache__` |
| 原生实现 | 避免重框架 |

**目标**: 冷启动 < 500ms

### 7.2 Token 优化

| 策略 | 说明 |
|------|------|
| 上下文合并 | 一次请求处理多个 Tool Calls |
| 输出截断 | 命令输出限制长度 |
| 增量上下文 | 仅传递必要文件内容 |
| 缓存机制 | 缓存项目结构信息 |

### 7.3 流式输出

```python
async def stream_response(response):
    """实时流式输出 LLM 响应"""
    async for chunk in response:
        if chunk.choices[0].delta.content:
            console.print(chunk.choices[0].delta.content, end="")
```

---

## 8. 技术栈总结

| 层级 | 技术 | 版本要求 |
|------|------|---------|
| 语言 | Python | >= 3.9 |
| CLI | Typer | >= 0.9 |
| 终端 UI | Rich | >= 13.0 |
| HTTP | httpx | >= 0.25 |
| LLM | LiteLLM | >= 1.40 |
| 配置 | PyYAML | >= 6.0 |
| 验证 | Pydantic | >= 2.0 |

---

## 9. 已实现功能

### 9.1 CLI 命令
- `llc chat` - 对话命令 (含 thinking 支持)
- `llc edit` - 文件编辑
- `llc task` - 复杂任务 (多 Agent 协作)
- `llc test` - 测试框架检测/运行/生成
- `llc config` - 配置管理

### 9.2 支持的 LLM Provider
- GLM (智谱) - `GLM_API_KEY`
- OpenAI - `OPENAI_API_KEY`
- LiteLLM Proxy

### 9.3 Thinking 模型支持
- GLM: glm-z1-flash, glm-z1-air (`<think>` 标签格式)
- DeepSeek: deepseek-reasoner, deepseek-r1 (`reasoning_content` 字段)

### 9.4 Test 命令功能
- 测试框架检测 (pytest, unittest, jest, vitest, mocha, go test, cargo test)
- 测试执行 (支持 coverage, watch 模式)
- AI 测试生成 (使用 TesterAgent)

### 9.5 单元测试
- 测试框架: pytest + pytest-asyncio + pytest-cov
- 测试覆盖率: 36% (161 测试用例)
- 测试文件:
  - `tests/test_thinking_strategy.py` - Thinking 策略测试
  - `tests/test_test_cmd.py` - 测试命令测试
  - `tests/test_config_loader.py` - 配置加载测试
  - `tests/test_tools_base.py` - 工具基类测试
  - `tests/test_tokens.py` - Token 统计测试
  - `tests/test_github_copilot.py` - GitHub Copilot 认证测试
  - `tests/test_mcp.py` - MCP 模块测试 (含连接状态测试)

### 9.6 MCP (Model Context Protocol) 集成
- HTTP 传输: Streamable HTTP + JSON-RPC 2.0
- Stdio 传输: 子进程 stdin/stdout 通信
- 支持智谱 GLM web_reader 等远程 MCP 服务器
- 支持本地 MCP 服务器 (如 mcp-searxng)
- 工具自动注册到 Agent 工具系统

---

## 10. MCP 架构设计

### 10.1 MCP 概述

MCP (Model Context Protocol) 是 Anthropic 推出的模型上下文协议，
允许 AI 模型通过标准化接口访问外部工具和数据源。

MaxAgent 实现了完整的 MCP 客户端支持，包括两种传输方式：

### 10.2 传输类型

```
┌─────────────────────────────────────────────────────────────────┐
│                      MCP 传输架构                                │
└─────────────────────────────────────────────────────────────────┘

┌──────────────────────┐         ┌──────────────────────┐
│   HTTP 传输           │         │   Stdio 传输          │
│  (远程 MCP 服务器)     │         │  (本地 MCP 服务器)     │
├──────────────────────┤         ├──────────────────────┤
│  • JSON-RPC 2.0      │         │  • JSON-RPC 2.0      │
│  • Streamable HTTP   │         │  • stdin/stdout      │
│  • SSE 响应支持       │         │  • 子进程管理         │
│  • Session 管理       │         │  • 环境变量传递       │
└──────────────────────┘         └──────────────────────┘
          │                               │
          └───────────┬───────────────────┘
                      │
                      ▼
         ┌──────────────────────┐
         │   MCPClientBase      │
         │   (抽象基类)          │
         ├──────────────────────┤
         │  • connect()         │
         │  • list_tools()      │
         │  • call_tool()       │
         │  • close()           │
         └──────────────────────┘
                      │
                      ▼
         ┌──────────────────────┐
         │  create_mcp_client() │
         │     (工厂函数)        │
         └──────────────────────┘
```

### 10.3 MCP 模块结构

```
src/maxagent/mcp/
├── __init__.py         # 模块导出
├── config.py           # 配置管理
│   ├── MCPServerConfig   # 服务器配置类
│   └── MCPConfig         # 配置容器
├── client.py           # MCP 客户端
│   ├── MCPClientBase     # 抽象基类
│   ├── MCPHttpClient     # HTTP 传输客户端
│   ├── MCPStdioClient    # Stdio 传输客户端
│   └── create_mcp_client # 工厂函数
└── tools.py            # 工具集成
    ├── MCPTool           # BaseTool 包装类
    └── MCPToolRegistry   # MCP 工具注册表
```

### 10.4 工具集成流程

```
┌─────────────────────────────────────────────────────────────────┐
│                    MCP 工具集成流程                              │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │  加载 MCP 配置   │
                    │  MCPConfig.load │
                    └─────────────────┘
                              │
                              ▼
              ┌───────────────────────────────┐
              │  遍历启用的 MCP 服务器         │
              └───────────────────────────────┘
                              │
          ┌───────────────────┼───────────────────┐
          ▼                   ▼                   ▼
   ┌─────────────┐     ┌─────────────┐     ┌─────────────┐
   │ HTTP 服务器  │     │ Stdio 服务器 │     │    ...     │
   └─────────────┘     └─────────────┘     └─────────────┘
          │                   │                   │
          ▼                   ▼                   ▼
   ┌─────────────┐     ┌─────────────┐     ┌─────────────┐
   │ MCPHttpClient│    │MCPStdioClient│    │    ...     │
   └─────────────┘     └─────────────┘     └─────────────┘
          │                   │                   │
          └───────────────────┼───────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │   list_tools()  │
                    │   获取工具定义   │
                    └─────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │   MCPTool 包装   │
                    │  转换为 BaseTool │
                    └─────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │ 注册到 Agent    │
                    │  ToolRegistry   │
                    └─────────────────┘
```

### 10.5 使用示例

#### HTTP 传输 (智谱 GLM web_reader)

```bash
# 添加服务器
llc mcp add web-reader https://open.bigmodel.cn/api/mcp/web_reader/mcp \
    --header "Authorization: Bearer ${ZHIPU_KEY}"

# 测试连接
llc mcp test web-reader

# 在对话中使用
llc chat "Use web-reader to fetch https://example.com"
```

#### Stdio 传输 (本地 mcp-searxng)

```bash
# 安装 MCP 服务器
pip install mcp-searxng

# 添加服务器
llc mcp add searxng --command mcp-searxng \
    --env "SEARXNG_URL=http://192.168.31.205:8888"

# Claude 兼容语法 (使用 -- 分隔符)
llc mcp add searxng --transport stdio -- env SEARXNG_URL=http://192.168.31.205:8888 mcp-searxng

# 测试连接
llc mcp test searxng

# 在对话中使用
llc chat "Search for Python tutorials"
```

#### 列出服务器和连接状态

```bash
# 列出所有服务器并自动测试连接状态
llc mcp list

# 输出示例:
# Testing server connections...
#
#                                   MCP Servers                                   
# ┏━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┓
# ┃ Name       ┃ Type  ┃ URL/Command    ┃ Status  ┃ Connection   ┃
# ┡━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━┩
# │ web-reader │ http  │ https://open.… │ Enabled │ OK (1 tools) │
# │ searxng    │ stdio │ mcp-searxng    │ Enabled │ OK (2 tools) │
# └────────────┴───────┴────────────────┴─────────┴──────────────┘

# 详细模式显示环境变量和错误信息
llc mcp list -v

# 跳过连接测试快速列出
llc mcp list --no-test
```

---

## 11. 下一步开发计划

详见 TODO.md
