上下文汇总工具

输入：一段对话历史 + 当前轮对话；
输出：一个“浓缩版的可用上下文”（摘要），外加一份“可被检索的长期记忆”。

⸻

一、整体业务流程（从触发到产出）

从业务角度，这个工具每次运行大致经过 7 步：
	1.	触发条件判断
决定“要不要现在做压缩”。
	•	对话轮数超过 N（比如超过 20 轮）
	•	文本长度 / token 超过某个阈值
	•	用户显式说“这阶段总结一下”“帮我整理一下刚才的内容”
满足任意一条，就触发上下文工具。
	2.	收集本次需要处理的对话
	•	拿到当前会话中要处理的消息（可能是整个会话，也可能是最近 N 轮）。
	•	保留 role（谁说的）、时间顺序等信息。
	3.	对话分段（切成小片段）
	•	合并连续同一个说话方的多条消息。
	•	再按句子、换行、代码块、列表等拆成更细的「片段」。
	•	每个片段是之后分析的“最小单位”。
	4.	片段分类 + 重要性打分
对每一个片段，回答三件事：
1）它是什么类型的信息？
2）它重要不重要？
3）如果重要，它应该归到哪个“摘要栏目”里？
	5.	去重、合并与冲突处理
	•	把重复说过的话合并。
	•	对“需求多次修改”的情况，保留“最新版本 + 演变脉络”。
	•	删除无意义的冗余片段。
	6.	生成结构化摘要（可直接给 Agent 用的短上下文）
	•	按预设结构，把信息填进对应的栏目，比如：目标、背景、关键信息、约束、决策、TODO、代码片段等。
	•	同时生成“短摘要”（几句话）+“详细摘要”（结构化列表）。
	7.	形成长期记忆条目（可检索）
	•	把本次抽取出来的关键信息，做成一条或多条“记忆卡片”。
	•	每条记忆卡片记录：内容、来源片段、所属会话、时间等。
	•	为以后搜索做准备（关键词 + 语义检索）。

后续任何时候，当 Agent 需要“回想之前说过的某个东西”，只是通过查询这些记忆卡片，再找到对应源对话即可。

⸻

二、核心业务逻辑：一段对话是如何被“理解”的？

1. 对话分段逻辑

目的：把长长的聊天记录拆成有意义的小块，为后续打标签和评分做准备。

具体逻辑：
	1.	按说话方聚合：
	•	连续多条 user 消息合并成一个大块（比如用户连发三条补充需求）。
	•	连续多条 assistant 消息合并成一个大块（比如一个长回答被拆分成几条）。
	2.	按内容结构再细分：
	•	遇到明显的分隔：空行、列表项、代码块、SQL、JSON、Markdown 标题等 → 单独成段。
	•	长句按标点（句号、问号等）拆成多句。
	•	一段里如果既有自然语言又有代码/SQL，拆成“描述段”和“代码段”两段处理。
	3.	建立片段编号与位置映射：
	•	每个片段都有一个唯一 ID（比如 S12），同时记录“来自第几轮对话、第几条消息、哪一段”。

后面所有的标签、记忆，都指向这些片段 ID，保证可追溯。

⸻

2. 片段分类算法（“这段话属于哪一类？”）

对每一个片段，先判断它属于哪种“业务意义上的类型”，例如：
	•	目标 / 需求（Goal / Requirement）
	•	背景说明（Background）
	•	事实信息（Fact）
	•	推理过程 / 分析（Reasoning）
	•	决策 / 结论（Decision）
	•	约束条件（Constraint）
	•	操作步骤 / 计划（Steps / Plan）
	•	代码 / SQL / 配置（Code / SQL / Config）
	•	错误信息 / 日志（Error / Log）
	•	TODO / 待办（TODO）
	•	闲聊 / 情绪表达 / 寒暄（Chit-chat / Emotion）

分类逻辑（业务+算法结合）：
	1.	规则层：看特征和关键词
	•	包含明显的代码格式 → Code / SQL
	•	有“我现在想做的是”“我的需求是”“请帮我实现” → Goal / Requirement
	•	有“下一步”“计划”“步骤” → Steps / Plan
	•	有“结论是”“所以我们决定”“最终选择” → Decision
	•	有“必须”“不能”“限制”“只能用 XX” → Constraint
	•	有“报错”“Error”“Exception”“stack trace” → Error / Log
	•	含大量 ID / 数字（如账号、Jira 号、金额） → Fact
	•	出现“TODO”“后面要做”“记得” → TODO
	•	有“谢谢”“哈哈”“有点难过” → Chit-chat / Emotion
	2.	模型层：模糊情况交给 LLM 判断
	•	对于规则不好判的段落，把候选类型给模型投票：
“这段文本更像是：需求说明 / 背景介绍 / 分析 / 闲聊？”
	•	最终取置信度最高的类型。

每个片段得到一个主类型（也可以允许附加次要标签）。

⸻

3. 重要性打分算法（“值不值得保留？”）

对已分类的片段做“价值评估”，输出一个重要性等级：高 / 中 / 低。

打分维度：
	1.	类型权重（最重要的一条）
	•	高权重类型：Goal、Decision、Constraint、TODO、Code/SQL、关键 Facts
	•	中权重类型：Reasoning、Background、Steps
	•	低权重类型：Chit-chat、情绪表达、无信息确认
	2.	位置权重（在对话中的位置）
	•	最近几轮的内容相对更重要（尤其是用户最新需求、最后做的决策）。
	•	多次重复出现的信息，如果出现在后面，说明是“最新版本”。
	3.	引用关系权重
	•	如果一个片段被后面的对话多次提到或依赖，代表它是“被引用多的核心节点”，应提高权重。
	4.	信息密度
	•	包含大量具体信息（数字、ID、参数、步骤）的片段，权重提高。
	•	只有泛泛而谈但没有具体结论的片段，权重降低。

决策逻辑示例：

可以简单想象成一个规则表：
	•	类型为 Goal / Decision / Constraint / TODO / Code / SQL → 基础评分高
	•	类型为 Reasoning / Background / Steps → 基础评分中等
	•	类型为 Chit-chat / Emotion → 基础评分低
	•	最近 N 轮内的片段 → +偏置分
	•	被多次引用（后续片段有“如前面说的…”，“还是按刚才那个 SQL…”） → +偏置分
	•	非常长但信息重复 → -偏置分

最后按总分划分：
	•	≥ 阈值1 → 高重要性 → 必须进摘要
	•	介于 阈值2–阈值1 → 中重要性 → 视摘要长度决定是否精简保留
	•	< 阈值2 → 低重要性 → 可以丢弃或高度压缩为一句话

⸻

4. 去重与合并逻辑（“说了很多遍的东西怎么处理？”）

场景：
用户多次修改需求、多次重复同一个信息，多轮对话中纠结来回。

业务规则：
	1.	规则 1：保留演变过程的“关键节点”，删除无意义重复
	•	如果一个需求被多次重复、文字基本一致 → 只保留最新一次，前面几次合并为一句：
	•	如：“用户多次强调需要支持本地运行大模型。”
	2.	规则 2：对“版本变更”的需求，保留关键版本
	•	典型例子：“一开始要做 A，后来改成 B，再改成 C。”
	•	摘要中可以这样呈现：
	•	初始需求：A
	•	中间变更：B
	•	最终需求（当前生效）：C
	•	算法上，就是识别“同一主题”下的多个 Goal 片段，根据时间顺序只明确标注最终版本，并在背景中简要注明演变。
	3.	规则 3：相似事实合并
	•	多条事实内容非常接近，只是一些表达不同 → 合并为一条，列出最完整的信息版本。

⸻

5. 结构化摘要生成逻辑（“最后那份短上下文怎么拼出来？”）

当所有片段都有了类型和重要性后，开始组装“结构化摘要”。

摘要的典型结构可以是：
	•	当前目标（Current Goal）
	•	背景（Background）
	•	已确认的关键信息 / 事实（Key Facts）
	•	约束条件（Constraints）
	•	已做出的决策（Decisions）
	•	待办 / 下一步（TODOs / Next Steps）
	•	重要代码 / SQL / 配置片段（Important Snippets）

生成流程：
	1.	按类型分桶
	•	所有 Goal 片段 → 合并、重写成“当前目标 + 变化历史简述”。
	•	Constraint 片段 → 列一个清单。
	•	Decision 片段 → 按时间顺序列出关键决策。
	•	TODO 片段 → 提取为明确的待办列表。
	•	Code/SQL 片段 → 提取重要段落，给一个简短说明。
	2.	用自然语言重写成简洁条目
	•	每条尽量独立、清晰，“一条信息一句话”。
	•	例如：
	•	关键信息：
	•	用户有两张 5060Ti 16G 显卡，主要需求是本地运行大语言模型。
	•	约束：
	•	希望尽量减少额外硬件投入，优先利用现有配置。
	3.	生成两个层次的摘要：
	•	极短摘要（几句话，概述）：方便 Agent 快速知道“我现在在处理什么”。
	•	详细摘要（结构化列表）：在需要时可以全文加入到 prompt。

⸻

6. 长期记忆条目的业务逻辑（“以后怎么回忆？”）

每次压缩后，你会产生若干“记忆卡片”。一张记忆卡片可以理解为：

“在某个时间点，我们有过这样一段重要结论/事实/配置。”

记忆卡片应至少包含：
	•	核心内容：一段简洁的自然语言总结
	•	类型/标签：如“需求”“SQL”“配置”“决策”“账号信息”
	•	来源：对应的片段 ID、会话标识、时间
	•	相关主题标签：例如“显卡选型”“FNZ Jira 票据分析”等

之后的业务流程是：
	1.	用户在未来某一天问：“我们之前讨论本地跑 LLM 时怎么选 GPU 的？”
	2.	Agent 把这句话交给“记忆搜索算法”。

⸻

三、记忆搜索算法（“在一堆历史中找到相关信息”）

记忆搜索分两层逻辑：先筛，再排序。

1. 查询理解

对用户当前的问题进行理解，提取：
	•	主题关键词（如：GPU、显卡、本地 LLM、FNZ、Jira 号等）
	•	查询意图类型（找结论？找 SQL？找配置？找过去的需求？）

这一步的输出决定后面的检索侧重点和排序策略。

⸻

2. 粗筛选（关键词 / 标签过滤）

先用简单但高效的方法过滤掉大部分无关记忆：
	•	按标签过滤：
	•	如果问题中出现“SQL”，先只看标签里含 SQL / 数据库的记忆卡片。
	•	按关键词过滤：
	•	使用关键词匹配（Jira 号、型号、ID 等）找出显然相关的记忆。

这一步的目标是：从“大海”中先捞出“一小盆水”。

⸻

3. 精排序（语义相似度排序）

在粗筛出的记忆条目群里，再做“语义相似度”的比较：
	•	把用户当前的问题和每条候选记忆都转成某种“语义表示”（向量）。
	•	计算它们之间的相似度分数。
	•	按分数从高到低排序，取前 K 条作为结果。

从业务角度理解就是：

“在所有历史记忆中，找出最像你现在这个问题的那几条。”

⸻

4. 结果后处理（防错 + 合并）

拿到若干条高分记忆后，还有几步业务处理：
	1.	去重复：如果多条记忆内容非常接近，只保留一条。
	2.	按时间顺序排布：方便你看到事情的演变。
	3.	必要时合并成一段更完整的“回顾摘要”：
	•	在返回给 Agent 前，可以先让模型把这几条记忆融合为一个“历史回顾段落”。

最终留给 Agent 的，是“跟当前问题最相关的历史知识”，而非原原本本的全部老对话。

⸻

四、从你的视角，这个工具“应该做到的效果”

用一句比较“业务味”的话总结：

任何时候，当你或你的 Agent 在一个长对话中迷路、忘了前面说了什么、害怕 token 爆掉时，只要调用这个工具，就能得到：
	•	一份“当前任务的清晰、结构化摘要”，可以继续往下推；
	•	一批“可随时搜索的历史记忆卡片”，以后随时回来查。

整个过程关键就三个逻辑：
	1.	识别什么是“有价值的信息”（分类 + 打分）
	2.	如何把这些信息用结构化方式表示出来（摘要生成）
	3.	如何在将来快速从历史里捞出来（搜索算法）

你后面无论是用什么框架、什么数据库、什么模型，这三个逻辑不变，只是实现方式不同而已。
